<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Quantitative Text Analysis in R</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <meta name="description" content="Quantitative Text Analysis in R"/>
    <meta name="generator" content="xaringan and remark.js"/>
    <meta name="github-repo" content="favstats/xxx"/>
    <meta name="twitter:title" content="Quantitative Text Analysis in R"/>
    <meta name="twitter:description" content="Quantitative Text Analysis in R"/>
    <meta name="twitter:url" content="https://www.favstats.eu"/>
    <meta name="twitter:card" content="summary_large_image"/>
    <meta name="twitter:creator" content="@favstats"/>
    <meta name="twitter:site" content="@favstats"/>
    <meta property="og:title" content="Quantitative Text Analysis in R"/>
    <meta property="og:description" content="Quantitative Text Analysis in R"/>
    <meta property="og:url" content="https://www.favstats.eu"/>
    <meta property="og:type" content="website"/>
    <meta property="og:locale" content="en_US"/>
    <meta property="article:author" content="Fabio Votta"/>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-clipboard/xaringanExtra-clipboard.js"></script>
    <script>window.xaringanExtraClipboard(null, {"button":"Copy Code","success":"Copied!","error":"Press Ctrl+C to Copy"})</script>
    <link href="libs/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/styles.css" type="text/css" />
    <link rel="stylesheet" href="css/fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">



layout: true



&lt;style&gt;

 .tab { margin-left: 40px; }

.onehundredtwenty {
  font-size: 120%;
   }

&lt;style&gt;
.ninety {
  font-size: 90%;
   }

.eightyfive {
  font-size: 85%;
   }
   
.eighty {
  font-size: 80%;
   }
   
.seventyfive {
  font-size: 75%;
   }
   
.seventy {
  font-size: 70%;
   }
   
.fifty {
  font-size: 50%;
   }
   
.forty {
  font-size: 40%;
   }
&lt;/style&gt;










---
name: title-slide
class: title-slide, center, middle


&lt;div class="my-logo-right"&gt;&lt;/div&gt; 

&lt;br&gt;

# .font150[.fancy[Quantitative Text Analysis in R]] 

### .font120[.fancy[A gentle hands-on introduction]]

*Spring Camp University of Warwick*

Instructor: Fabio Votta

[<svg aria-hidden="true" role="img" viewBox="0 0 512 512" style="height:1em;width:1em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;"><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg> @favstats](http://twitter.com/favstats)&lt;br&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg> @favstats](http://github.com/favstats)&lt;br&gt;
[<svg aria-hidden="true" role="img" viewBox="0 0 496 512" style="height:1em;width:0.97em;vertical-align:-0.125em;margin-left:auto;margin-right:auto;font-size:inherit;fill:white;overflow:visible;position:relative;"><path d="M336.5 160C322 70.7 287.8 8 248 8s-74 62.7-88.5 152h177zM152 256c0 22.2 1.2 43.5 3.3 64h185.3c2.1-20.5 3.3-41.8 3.3-64s-1.2-43.5-3.3-64H155.3c-2.1 20.5-3.3 41.8-3.3 64zm324.7-96c-28.6-67.9-86.5-120.4-158-141.6 24.4 33.8 41.2 84.7 50 141.6h108zM177.2 18.4C105.8 39.6 47.8 92.1 19.3 160h108c8.7-56.9 25.5-107.8 49.9-141.6zM487.4 192H372.7c2.1 21 3.3 42.5 3.3 64s-1.2 43-3.3 64h114.6c5.5-20.5 8.6-41.8 8.6-64s-3.1-43.5-8.5-64zM120 256c0-21.5 1.2-43 3.3-64H8.6C3.2 212.5 0 233.8 0 256s3.2 43.5 8.6 64h114.6c-2-21-3.2-42.5-3.2-64zm39.5 96c14.5 89.3 48.7 152 88.5 152s74-62.7 88.5-152h-177zm159.3 141.6c71.4-21.2 129.4-73.7 158-141.6h-108c-8.8 56.9-25.6 107.8-50 141.6zM19.3 352c28.6 67.9 86.5 120.4 158 141.6-24.4-33.8-41.2-84.7-50-141.6h-108z"/></svg> favstats.eu](https://www.favstats.eu)


29th June 2022 (Day 2)

.fifty[Link to slides: [favstats.github.io/WarwickSpringCamp_QTA/slides/day2/](https://favstats.github.io/WarwickSpringCamp_QTA/slides/day2/)]

---

### Overview Day 2 (10:00 to 16:00)

+ Part-of-speech tagging
  + Keyword extraction
  + RAKE, Noun phrases, dependency parisng
  
15   M I N U T E S   B R E A K:   *10:45*

+ Project (45 minutes time)

1   H O U R   B R E A K:   *12:00*

+ Unsupervised Machine Learning (Topic Modelling) *13:00*
  
15   M I N U T E S   B R E A K:   *14:00*

+ Supervised Machine Learning

+ Project (45 minutes time)

*15 minutes for presentations*


---

class: center, middle

# Part-of-speech tagging

&lt;center&gt;

&lt;img src="https://i2.wp.com/www.bnosac.be/images/bnosac/blog/depenceny-parsing-example3.png?w=584"&gt;

  
&lt;/center&gt;

---


## Part-of-speech tagging

&gt; Part-of-speech tagging is the process of assigning a syntactic tag to each word in a sentence. 

For example, in the sentence: 

`"The dog chased the cat."`

1. "dog" and "cat" would be assigned the tag "noun"

2. "chased" would be assigned the tag "verb." 

The most common parts of speech are nouns, verbs, adjectives, adverbs, and pronouns, but there are many more!

---


## NLP with `udpipe`


&gt; "`udpipe` provides quick and simple annnotations giving rich output: tokenization, part-of-speech-tagging, lemmatization and dependency parsing with multi-language support. From raw text to parsed output for more than 50 languages."


```r
library(udpipe)
```


---

### NLP with `udpipe`

.font70[
*The* following table contains the so-called **universal part-of-speech tags** (upos). 

]

.font40[

| Universal POS tags | Meaning                   | Definition                                                                                                                                                                                                                      | Example                                                          |
|--------------------|---------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------|
| ADJ                | adjective                 | Adjectives are words that typically modify nouns and specify their properties or attributes:                                                                                                                                    | The car is **green**.                                            |
| ADP                | adposition                | In many languages, adpositions can take the form of fixed multiword expressions,                                                                                                                                                | **in** spite **of**, because **of**, thanks **to**               |
| ADV                | adverb                    | Adverbs are words that typically modify verbs for such categories as time, place, direction or manner.                                                                                                                          | He ate **slowly**.                                               |
| AUX                | auxiliary                 | An auxiliary is a function word that accompanies the lexical verb of a verb phrase and expresses&lt;br&gt;grammatical distinctions not carried by the lexical verb, such as person, number, tense, mood, aspect,&lt;br&gt;voice or evidentiality. | Tense auxiliaries: **has** (done), **is** (doing), **will** (do) |
| CCONJ              | coordinating conjunction  | A coordinating conjunction is a word that links words or larger constituents without syntactically&lt;br&gt;subordinating one to the other and expresses a semantic relationship between them.                                           | **and**, **or**, **but**                                         |
| DET                | determiner                | Determiners are words that modify nouns or noun phrases and express the reference of the noun phrase in context.                                                                                                                | **the**, **this**, **that**, **which**                           |
| INTJ               | interjection              | An interjection is a word that is used most often as an exclamation or part of an exclamation.                                                                                                                                  | **psst**, **ouch**                                               |
| NOUN               | noun                      | Nouns are a part of speech typically denoting a person, place, thing, animal or idea.                                                                                                                                           | The **cat** is in the **hat**.                                   |
| NUM                | numeral                   | A numeral is a word, functioning most typically as a determiner, adjective or pronoun, that expresses&lt;br&gt;a number and a relation to the number, such as quantity, sequence, frequency or fraction.                                 | **0**, **1**, **2**, **one**, **two**, **three**                 |
| PART               | particle                  | Particles are function words that must be associated with another word or phrase to impart meaning&lt;br&gt;and that do not satisfy definitions of other universal parts of speech                                                       | Possessive marker: [en] ‘s                                       |
| PRON               | pronoun                   | Pronouns are words that substitute for nouns or noun phrases, whose meaning is recoverable&lt;br&gt;from the linguistic or extralinguistic context.                                                                                      | personal pronouns: I, you, he, she, it, we, they                 |
| PROPN              | proper noun               | A proper noun is a noun (or nominal content word) that is the name (or part of the name)&lt;br&gt;of a specific individual, place, or object.                                                                                            | **London**, **NATO**, **Mary Sue**                               |
| PUNCT              | punctuation               | Punctuation marks are non-alphabetical characters and character groups used in many languages&lt;br&gt;to delimit linguistic units in printed text.                                                                                      | **,**, **.**, **(**, **:**                                       |
| VERB               | verb                      | A verb is a member of the syntactic class of words that typically signal events and actions                                                                                                                                     | He **runs**.                                                     |



]

---

### One function to rule them all: `udpipe()`

`udpipe()` is the main work horse of the `udpipe` package. With it you can perform

+ tokenization
+ lemmatization
+ part-of-speech tagging
+ dependency parsing

**all in one!**

&gt;  On dependency parsing:  dependency parsing is a type of syntactic parsing that identifies the dependencies between words in a sentence. Dependency parsers typically use a set of rules to find these dependencies, and these rules can vary depending on the language being parsed.


---

#### Trump tweet example


Let's apply `udpipe()` on the "nuclear" Trump tweet from yesterday and see what it can do for us!


```r
## read in Trump tweets
trump_tweets &lt;- readr::read_csv("https://raw.githubusercontent.com/favstats/WarwickSpringCamp_QTA/main/docs/slides/day1/data/trump_tweets.csv")


## nuclear tweet
trump_tweet &lt;- trump_tweets[trump_tweets$id == 1165918301932916736,]

trump_tweet$text
```

```
#&gt; [1] "The story by Axios that President Trump wanted to blow up large hurricanes with nuclear weapons prior to reaching shore is ridiculous. I never said this. Just more FAKE NEWS!"
```


---

#### Trump tweet example

.pull-left[

`udpipe()` expects a data.frame with two variables:

1. `doc_id`, a unique identifier for your document
2. `text`, the text you are trying to parse




```r
trump_tweet_ud &lt;- trump_tweet %&gt;%
  mutate(doc_id = id)

pos_tags_trump &lt;- udpipe(trump_tweet_ud, "english")

pos_tags_trump %&gt;%
  select(token, upos, lemma) %&gt;% kable()
```

]

.pull-right[



&lt;table class="table" style="font-size: 10px; margin-left: auto; margin-right: auto;"&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:left;"&gt; token &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; upos &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; lemma &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; dep_rel &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; The &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; DET &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; the &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; det &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; story &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; NOUN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; story &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; nsubj &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; by &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADP &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; by &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; case &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Axios &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PROPN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Axios &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; nmod &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; that &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; SCONJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; that &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; mark &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; President &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PROPN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; President &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; nsubj &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; Trump &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PROPN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Trump &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; flat &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; wanted &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; VERB &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; want &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; acl &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; to &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; PART &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; to &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; mark &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; blow &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; VERB &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; blow &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; xcomp &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; up &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADP &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; up &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; compound:prt &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; large &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; large &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; amod &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; hurricanes &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; NOUN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; hurricane &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; obj &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; with &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADP &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; with &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; case &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; nuclear &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; nuclear &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; amod &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; weapons &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; NOUN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; weapon &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; nmod &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; prior &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; prior &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; case &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; to &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; SCONJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; to &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; fixed &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; reaching &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; VERB &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; reache &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; amod &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; shore &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; NOUN &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; shore &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; advcl &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; is &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; AUX &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; be &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; cop &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; ridiculous &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ADJ &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; ridiculous &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; root &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;


]


---

### Visualizing the nice tidy data frame that `udpipe()` puts out

.font50[
We can visualize all the output from `udpipe()` using the function (taken from [here](https://www.r-bloggers.com/2019/07/dependency-parsing-with-udpipe/#:~:text=Dependency%20parsing%20is%20an%20NLP,you%20further%20details%20about%20it.)).
]



![](https://pbs.twimg.com/media/FWAb-SFX0AAzW4n?format=jpg&amp;name=large)

---

### Keyword extraction

.font80[


Now we have tags for our text. Brilliant. What can we do with this? 

Similar as before, we are interested in what's going on in our text. 

Part-of-speech tagging can enable us to find more meaningful keywords that tell us something about the texts we are investigating.

`udpipe()` offers various methods for keyword extractions:


1.   Find keywords by doing **parts of speech tagging in order to identify nouns**
2. Find keywords based on **collocations and co-occurrences**
3. Find keywords based on algorithms
  * **RAKE** (rapid automatic keyword extraction)
4. Find keywords by looking for **phrases** (e.g. noun phrases)
5. Find keywords based on results of **dependency parsing** (getting the subject of the text)


]


---

#### Most frequent nouns/verbs etc.

Let's now run part-of-speech tagging to find the most common nouns and verbs that Trump uses.


```r
# This takes a couple of minutes

trump_tweets_uds &lt;- trump_tweets %&gt;%
  filter(date_year %in% 2016:2021) %&gt;%
  mutate(doc_id = id)  %&gt;%
  mutate(doc_id = as.character(doc_id))

pos_tags_trump_all &lt;- udpipe(trump_tweets_uds, "english")  %&gt;%
  left_join(trump_tweet_ud)
```




---

#### Most frequent nouns



```r
pos_tags_trump_all %&gt;%
  filter(upos == "NOUN") %&gt;%
  count(token, sort = T) %&gt;%
  head(10)  %&gt;% 
  mutate(word_n = paste0(token, ": ", n)) %&gt;% 
  pull(word_n)
```

```
#&gt;  [1] "amp: 3195"       "people: 2117"    "time: 1011"      "years: 944"     
#&gt;  [5] "today: 880"      "Country: 860"    "Trump: 775"      "job: 765"       
#&gt;  [9] "WhiteHouse: 662" "country: 624"
```


---

#### Most frequent verbs




```r
pos_tags_trump_all %&gt;%
  filter(upos == "VERB") %&gt;%
  count(token, sort = T) %&gt;%
  head(10)  %&gt;% 
  mutate(word_n = paste0(token, ": ", n)) %&gt;% 
  pull(word_n)
```

```
#&gt;  [1] "RT: 2334"    "Thank: 1777" "have: 1591"  "get: 1093"   "do: 1027"   
#&gt;  [6] "want: 973"   "going: 893"  "has: 799"    "doing: 771"  "done: 713"
```

---

#### RAKE (rapid automatic keyword extraction)

&gt; RAKE is a basic algorithm which tries to identify keywords in text. Keywords are defined as a sequence of words following one another. 

Frequency of occurence plays a role as well, as well as frequency of co-occurences with other words. Word combinatiosn with higher values are considered to be more frequent and unique.

If you want to know more about RAKE [see here](https://www.analyticsvidhya.com/blog/2021/10/rapid-keyword-extraction-rake-algorithm-in-natural-language-processing/).


---

#### RAKE (rapid automatic keyword extraction)

.panelset[
.panel[.panel-name[Extract RAKE]



```r
## Using RAKE
rake_keys &lt;- keywords_rake(
  x = pos_tags_trump_all %&gt;% mutate(lemma = stringr::str_to_lower(lemma)), 
  term = "lemma", group = "doc_id", 
  relevant = pos_tags_trump_all$upos %in% c("NOUN", "VERB", "ADJ")
  )
```

]


.panel[.panel-name[Visualization code]


```r
library(ggplot2)


#stats
rake_keys %&gt;% 
  filter(freq &gt; 5) %&gt;%
  arrange(-rake) %&gt;%
  mutate(keyword = forcats::fct_reorder(keyword, rake)) %&gt;%
  slice(1:20) %&gt;%
  ggplot(aes(keyword, rake)) +
  geom_col() +
  coord_flip() +
  theme_minimal()
```

]


.panel[.panel-name[Visualization]

&lt;img src="figs/unnamed-chunk-11-1.png" width="522.144" /&gt;

]

]

---

#### (Simple) Noun Phrases



Next option is to extract (simple) noun phrases. What are they?

Noun phrases are groups of words that function like nouns.

Some examples:

**All the children** were eating.

She bought herself **a beautiful dark dress**.

Dad baked **a tasty chocolate cake**.



---

#### (Simple) Noun Phrases

.font80[

How does this work? Parts of Speech tags are recoded to one of the following one-letters: 

&gt; A: adjective, C: coordinating conjuction, D: determiner, M: modifier of verb, N: noun or proper noun, P: pre/postposition. 

Next you can define a regular expression to indicate a sequence of parts of speech tags which you want to extract from the text.

As regex we can express a (simple) noun phrase as this:

&gt; `(A|N)*N(P+D*(A|N)*N)*`

For more info on noun phrases [see here](https://universaldependencies.org/workgroups/newdoc/simple_noun_phrases.html).

]


---


#### (Simple) Noun Phrases


```r
## Simple noun phrases (a adjective+noun, pre/postposition, optional determiner and another adjective+noun)
pos_tags_trump_all$phrase_tag &lt;- as_phrasemachine(pos_tags_trump_all$upos, type = "upos")

keyw_nounphrases &lt;- keywords_phrases(pos_tags_trump_all$phrase_tag, term = pos_tags_trump_all$token, 
                                     pattern = "(A|N)*N(P+D*(A|N)*N)*", is_regex = TRUE, 
                                     detailed = T)
```


---


#### Most common (simple) noun phrases


```r
keyw_nounphrases %&gt;%
  filter(ngram &gt;= 3) %&gt;%
  count(keyword, sort = T) %&gt;%
  head(20)  %&gt;% 
  mutate(keyword_n = paste0(keyword, ": ", n)) %&gt;% 
  pull(keyword_n)
```

```
#&gt;  [1] "AMERICA GREAT AGAIN: 303"           "RT @ TeamTrump: 247"               
#&gt;  [3] "Fake News Media: 233"               "Do Nothing Democrats: 114"         
#&gt;  [5] "New York Times: 107"                "my great honor: 103"               
#&gt;  [7] "RT @ IvankaTrump: 102"              "RT @ DanScavino: 97"               
#&gt;  [9] "RT @ TomFitton: 94"                 "Sleepy Joe Biden: 92"              
#&gt; [11] "RT @ DonaldJTrumpJr: 76"            "history of our: 73"                
#&gt; [13] "RT @ EricTrump: 72"                 "RT @ TrumpWarRoom: 70"             
#&gt; [15] "President of the United: 69"        "President of the United States: 69"
#&gt; [17] "Donald J. Trump: 67"                "your Second Amendment: 62"         
#&gt; [19] "Crooked Hillary Clinton: 61"        "Radical Left Democrats: 61"
```

---

#### Dependency Parsing

For this exercise we are going to take the words which have as dependency relation "*nsubj*" indicating the nominal subject and we are adding to that the adjective which is changing the nominal subject.



```r
stats &lt;- merge(pos_tags_trump_all, pos_tags_trump_all, 
           by.x = c("doc_id", "paragraph_id", "sentence_id", "head_token_id"),
           by.y = c("doc_id", "paragraph_id", "sentence_id", "token_id"),
           all.x = TRUE, all.y = FALSE, 
           suffixes = c("", "_parent"), sort = FALSE) 

stats &lt;- subset(stats, dep_rel %in% c("nsubj") &amp; upos %in% c("NOUN", "PROPN") &amp; upos_parent %in% c("ADJ"))

stats$term &lt;- paste(stats$lemma_parent, stats$lemma, sep = " ")
```

---


#### Dependency Parsing


```r
stats %&gt;%
  count(term, sort = T) %&gt;%
  head(20)   %&gt;% 
  mutate(term_n = paste0(term, ": ", n)) %&gt;% 
  pull(term_n)
```

```
#&gt;  [1] "corrupt media: 14"       "happy people: 9"        
#&gt;  [3] "strong economy: 9"       "angry people: 8"        
#&gt;  [5] "right Rt: 8"             "good number: 7"         
#&gt;  [7] "right President: 7"      "right Trump: 7"         
#&gt;  [9] "tired people: 7"         "underway voting: 7"     
#&gt; [11] "dead ObamaCare: 6"       "interested Democrats: 6"
#&gt; [13] "sick people: 6"          "stronger economy: 6"    
#&gt; [15] "amazing crowd: 5"        "bad news: 5"            
#&gt; [17] "best year: 5"            "better economy: 5"      
#&gt; [19] "lowest unemployment: 5"  "perfect call: 5"
```

---

class: center, middle, inverse

# Machine Learning

&lt;center&gt;

&lt;img src="https://i.gifer.com/fxvV.gif"&gt;

  
&lt;/center&gt;

---

## Machine Learning

&gt; Machine learning, broadly defined, are a range computational methods that can "learn" by discovering patterns in data.

There are two (for us relevant) methods how machines can learn:

1. *Unsupervised* machine learning (clustering)
2. *Supervised* machine learning (classification)



---

## Machine Learning

&gt; Machine learning, broadly defined, are a range computational methods that can "learn" by discovering patterns in data.

**Unsupervised machine learning (clustering)**

In *unsupervised learning* we let an algorithm figure out quantities of interest, solely by supplying it with the data.

Typically, this happens by identifiyng so-called *clusters* that are more similar to each other in some way, compared to other clusters.


---

## Machine Learning

&gt; Machine learning, broadly defined, are a range computational methods that can "learn" by discovering patterns in data.


**Supervised machine learning (classification)**

In *supervised learning* we provide a machine learning model with some data (*training data*) from which it can learn patterns.

For example, we may have some annotated tweets that tell us whether they are positive or negative. We can leverage that data to let a machine learning model learn the patterns of text that are positive vs. negative.

---

## Machine Learning

Most important thing to remember:

+ *Unsupervised* machine learning 

&lt;p class="tab"&gt;&amp;#8594; learns patterns by itself&lt;/p&gt;



+ *Supervised* machine learning (classification)



&lt;p class="tab"&gt;&amp;#8594; learns patterns based on provided (human) annotations&lt;/p&gt;




---

class: center, middle, inverse

# Topic Models

an .fancy[unsupervised machine learning] method

---


## Topic Models

.font80[
&gt; Topic models can be used to identify "topics" in (large corpora of) text. 


You may have noticed that I put "topics" in quotation marks. That is because the output of a topic model is not what one would *intuitively* understand as topic.

Here is an example output:
]



![](images/topics_output.png)

---

## Topic Models - Example

&gt; Jacobi, C., van Atteveldt, W., &amp; Welbers, K. (2015). Quantitative analysis of large amounts of journalistic texts using topic modelling. Digital Journalism, 4(1), 89–106. doi:10.1080/21670811.2015.1093271


*a case study of the New York Times coverage of nuclear technology from 1945*

---



## Jacobi et al.

![](images/Jacobi1.png)

---

## Jacobi et al.


&lt;img src="images/Jacobi2.png" width = "60%"&gt;



---

## Jacobi et al.


&lt;img src="images/Jacobi3.png" width = "80%"&gt;



---

## Jacobi et al.

![](images/Jacobi4.png)

---

## Jacobi et al.


&lt;img src="images/Jacobi5.png" width = "60%"&gt;


---

## Topic Models

We are going to take a look at Latent Dirichlet Allocation (LDA) in particular (a common implementation of topic modelling)

An LDA has two model assumptions:

+ every document can be represented as a distribution of topics - `\(\theta\)` (also sometimes called `\(\gamma\)`)

This means: every document consists of a range of topics

+ every topic can be represented as distribution of terms - `\(\beta\)`


This means: every topic consists of a range of terms

Another important parameter is `\(\alpha\)`, which regulates how topics cluster per document

---


## The conference table

What is a *latent dirichlet allocation*?

Often explained with the "conference table process":

1. You walk into a room for a conference dinner 

2. You don't want to sit alone

3. Everyone does the same as they enter

+ Empty tables stay empty, full tables get more people proportionally until equilibrium is reached

https://topicmodels.west.uni-koblenz.de/ckling/tmt/restaurant.html?parameters=1,1,1,1

---


## Dirichlet at an academic conference 

+ The conference dinner converges to a multinomial distribution

  + e.g. the topics per document, of words per topic

+ The initial number of people at the tables is the *alpha parameter*

+ Intuitive effect of lower alpha

  + initial choice of "conference attendees" have larger effect
  + likelier that a single table will get all participants
  
  
+ Lower alpha = fewer topics per document

  + but means topics have to include more words / have more overlap, as each word needs to be assigned

---


## You have to choose (the K)

As unsupervised methods, topic models do not know how many topics it should estimate

This is a parameter called *K*

Choosing K (how many topics you want to be estimated) is almost a science in itself

---


## Validating topic models

+ What does it mean "to measure a topic"

+ Three strategies

  + Face validity: inspect top terms, top documents, edge cases
  + Concurrent validity: does the model reproduce expert or gold-standard coding?
  + Construct validity: are topics *cohesive* and *distinctive*?
  
cohesive: coherent terms within topics

distinctive: distinctive from other topics

See: Chang et al. (2009): [Reading Tea Leaves: How Humans Interpret Topic Models](https://proceedings.neurips.cc/paper/2009/file/f92586a25bb3145facd64ab20fd554ff-Paper.pdf)

---

## Document-term matrix

Most topic models take data as a so-called "*document-term-matrix* (dtm). A dtm is a matrix (with rows and columns) that counts the number of times terms occur in specific documents.

This is what it looks like:

![](images/dtm.png)


---

.leftcol75[

## `debates` dataset

.font80[
`debates` provides easy access to debate transcripts from Presidential, Vice Presidential, and primary candidate debates. The current version includes Presidential and Vice-Presidential debate transcripts starting in 1960, and for most debates from the 2012, 2016, and 2020 primary elections.
]

]

.rightcol25[


&lt;img src="https://github.com/jamesmartherus/debates/raw/master/man/figures/logo.png" width="100" height="120" style="display: block; margin: auto 0 auto auto;" /&gt;

]

&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;br&gt;

&lt;br&gt;




.font70[
We will estimate topic models on the `debates` dateset. 

We could estimate our topic models using all the words within the documents but:

1. Many words will not be good indicators of a topic
2. It will take a long time

So for efficiency, we will **only keep lemmatized nouns** (as identified by POS tagging).

A similar approach has been taken by Jacobi et al., 2016, and Lind et al., 2021.

*continue in script topic_modelling.Rmd*

]






---


class: center, middle, inverse

# Supervised Machine Learning


---

## Supervised Machine Learning

&gt; Supervised machine learning is a type of machine learning algorithm that uses a labelled dataset to train a model to make predictions.

In comparison to unsupervised machine learning, supervised learning requires labels often provided by the researchers.

The labelled dataset is a collection of data that has been labelled with the desired outcome. 

The model is then able to use the labelled dataset to learn how to map the input data to the correct output. 


---


## Supervised Machine Learning

Similarities to typical statistical modelling

+ You can also use linear/logistic regression for machine learning

However: we are more interested in prediction, not explaining

Models may have 1000s of independent variables

We are not interested in the effects, but rather the outcome

---



## Supervised text classification

Supervised machine learning is a powerful tool for text classification. It can be used to automatically categorize texts into different classes. 

For example, it can be used to classifier emails into spam and non-spam, or articles into different topics. 

Another typical use-case for supervised ML is sentiment analysis.


---



## Main drivers of model performance

1. Task difficulty

2. Amount of training data

3. Choice of features (n-grams, lemmata, etc.)

4. Tuning of hyperparameters

---


## Train and Test data


Training data is the data that we use to train our models. This data is used to fit the model and is used to optimize its parameters. 

Test data is the data that we use to evaluate our trained model. This data is used to see how well the model performs on unseen data. 

It's important to have both training and test data because we want to make sure that our model is generalizable. 

That is, we want to make sure that our model can perform well on data that it hasn't seen before. 



---

### Prevent overfitting

![](https://docs.aws.amazon.com/machine-learning/latest/dg/images/mlconcepts_image5.png)
.font70[
+ Sufficiently complex model can "predict" all training data perfectly

+ However: our model would perform poorly on new, unseen data. This is called **overfitting**. 

+ Process:

1. Split data into train + test

2. Train model on training data

3. Test model on unseen test data
]





---

### What is cross-validation in supervised machine learning?

&gt; Cross-validation is a technique used to assess the accuracy of a model and prevent overfitting by repeatedly resampling the dataset and re-fitting the model.

.font80[
Why is cross-validation necessary?

Cross-validation is necessary because it provides a more accurate estimate of the model's performance than using the training set alone. It also helps to prevent overfitting.

What are the benefits of cross-validation?

- improved accuracy
- prevention of overfitting

What are the drawbacks of cross-validation?

- extra computational time
]



---

## Choosing model and hyperparameters

.font70[

Many different model types exist

+ Linear/logistic Regression, naive bayes, neural networks, etc.

They all come with different hyperparemeters

+ Learning rate, regularization, neural network structure

*What are hyperparameters?*

Hyperparameters are parameters, *settings*, that define the overall structure and behaviour of a machine learning model. 

They can significantly impact the performance of a machine learning model.

]

---


## Hyperparameters in Supervised Machine Learning


.font80[

*What are the benefits of tuning hyperparameters?*

Tuning hyperparameters can improve the performance of a machine learning model and make it more robust.

*What are the downsides of tuning hyperparameters?*

Tuning hyperparameters can be time-consuming and may not always lead to improved performance. 

*How can hyperparameters be tuned?*

Hyperparameters can be tuned using a variety of methods, including grid search, random search, and manual search.


]




*continue in script smltar.Rmd*


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"slideNumberFormat": "%current%<br>",
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<script>
  (function() {
    var divHTML = document.querySelectorAll(".details-open");
    divHTML.forEach(function (el) {
      var preNodes = el.getElementsByTagName("pre");
      var outputNode = preNodes[1];
      outputNode.outerHTML = "<details open class='output'><summary>Run</summary>" + outputNode.outerHTML + "</details>";
    })
  })();
(function() {
  var divHTML = document.querySelectorAll(".details");
  divHTML.forEach(function (el) {
    var preNodes = el.getElementsByTagName("pre");
    var outputNode = preNodes[1];
    outputNode.outerHTML = "<details class='output'><summary>Run</summary>" + outputNode.outerHTML + "</details>";
  })
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
